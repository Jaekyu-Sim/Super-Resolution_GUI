{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from PyQt5.QtWidgets import *\n",
    "from PyQt5 import uic\n",
    "from PyQt5.QtGui import *\n",
    "import PyQt5\n",
    "import tensorflow as tf\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#from PyQt5 import Qt\n",
    "\n",
    "UI_File = \"SuperResolution.ui\"\n",
    "UI_MainWindow, QtBaseClass = uic.loadUiType(UI_File)\n",
    "flags = tf.app.flags\n",
    "\n",
    "flags.DEFINE_boolean(\"is_train\", False, \"[True] -> training, [False] -> testing\")\n",
    "FLAGS = flags.FLAGS\n",
    "_image_data = 0\n",
    "\n",
    "class SR_Window(QMainWindow, UI_MainWindow):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.setupUi(self)\n",
    "        self.image_data = _image_data\n",
    "        self.Image_Load_Btn.clicked.connect(self.Image_Load_Btn_Clicked)\n",
    "        self.TransformButton.clicked.connect(self.Transform_Btn_Clicked)\n",
    "    def Image_Load_Btn_Clicked(self):\n",
    "        f_path = QFileDialog.getOpenFileName(self)\n",
    "        global file_path\n",
    "        file_path = f_path\n",
    "        image_data = QImage()\n",
    "        image_data.load(f_path[0])\n",
    "        image = QPixmap()\n",
    "        image = QPixmap.fromImage(image_data)\n",
    "\n",
    "        image = image.scaledToWidth(321)#, Qt.IgnoreAspectRatio)\n",
    "        image = image.scaledToHeight(271)#, Qt.IgnoreAspectRatio)#281\n",
    "\n",
    "        scene = QGraphicsScene()\n",
    "        #scene.setSceneRect(scene.itemsBoundingRect());\n",
    "        scene.addPixmap(image)\n",
    "        self.graphicsView.setScene(scene)\n",
    "    def Transform_Btn_Clicked(self):\n",
    "        global _image_data\n",
    "        img_data = [None]\n",
    "        input_data = [None]\n",
    "        tmp_data = [None]\n",
    "        label_data = [None]\n",
    "        img_data = misc.imread(\"%s\"%(file_path[0]))\n",
    "        tmp_data = misc.imresize(img_data, (120, 120))\n",
    "        input_data = misc.imresize(tmp_data, (120, 120))#처음 망에 들어가는 이미지 (blur)\n",
    "        label_data = misc.imresize(img_data, (120, 120))#label 이미지 (선명)\n",
    "        #print(img_data)\n",
    "        with tf.Session() as sess:\n",
    "            srcnn = SRCNN(sess = sess, input_data = input_data, label_data = label_data, label_size = 120, input_size = 120, input_img_channel=3)\n",
    "            srcnn.training(FLAGS)\n",
    "\n",
    "            _image_data = (srcnn.transform_image_high_quality([input_data]))\n",
    "            misc.imsave(\"img_transform.bmp\", _image_data)\n",
    "            \n",
    "            path = \"./img_transform.bmp\"\n",
    "        \n",
    "            image_data = QImage()\n",
    "            image_data.load(path)\n",
    "            image = QPixmap()\n",
    "            image = QPixmap.fromImage(image_data)\n",
    "\n",
    "            image = image.scaledToWidth(321)#, Qt.IgnoreAspectRatio)\n",
    "            image = image.scaledToHeight(271)#, Qt.IgnoreAspectRatio)#281\n",
    "\n",
    "            scene2 = QGraphicsScene()\n",
    "            #scene.setSceneRect(scene.itemsBoundingRect());\n",
    "            scene2.addPixmap(image)\n",
    "            self.graphicsView_2.setScene(scene2)\n",
    "\n",
    "\n",
    "class SRCNN(object):\n",
    "    def __init__(self, sess, input_data, label_data, input_size, label_size, input_img_channel):\n",
    "        self.sess = sess\n",
    "        self.input_data = input_data\n",
    "        self.label_data = label_data\n",
    "        self.input_size = input_size#100\n",
    "        self.label_size = label_size#120\n",
    "        self.channel_dim = input_img_channel\n",
    "        self.parameter()\n",
    "        self.model()\n",
    "        #self.training()\n",
    "    \n",
    "    \n",
    "    def parameter(self):\n",
    "        self.X = tf.placeholder(dtype=tf.float32, shape=[None, self.input_size, self.input_size, self.channel_dim])\n",
    "        self.Y = tf.placeholder(dtype=tf.float32, shape=[None, self.label_size, self.label_size, self.channel_dim])\n",
    "        #9x9크기, 3개의 채널, n1=64개의 필터를 가지는 커널.\n",
    "        self.W1 = tf.Variable(tf.random_normal(shape=[9, 9, self.channel_dim, 64], stddev=1e-03))#shape=[9, 9, 3, 64]\n",
    "        self.b1 = tf.Variable(tf.zeros(shape=[64]))\n",
    "        \n",
    "        self.W2 = tf.Variable(tf.random_normal(shape=[1, 1, 64, 32], stddev=1e-03))\n",
    "        self.b2 = tf.Variable(tf.zeros(shape=[32]))\n",
    "        \n",
    "        self.W3 = tf.Variable(tf.random_normal(shape=[5, 5, 32, self.channel_dim], stddev=1e-03))\n",
    "        self.b3 = tf.Variable(tf.zeros(shape=[self.channel_dim]))\n",
    "        \n",
    "    def model(self):\n",
    "        #일단 1,1,1,1 로 stride 선택\n",
    "        self.L1 = tf.nn.conv2d(self.X, self.W1, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        self.Y1 = tf.nn.relu(self.L1)\n",
    "        \n",
    "        self.L2 = tf.nn.conv2d(self.Y1, self.W2, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        self.Y2 = tf.nn.relu(self.L2)\n",
    "        \n",
    "        self.model = tf.nn.conv2d(self.Y2, self.W3, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        \n",
    "        self.cost = tf.reduce_mean(tf.square(self.Y - self.model))\n",
    "        \n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=1e-3).minimize(self.cost)\n",
    "        \n",
    "    def training(self, config):\n",
    "        #3572 -> training 이미지 데이터 갯수, 32 -> batch size\n",
    "        total_batch = int(3572 / 32)\n",
    "        SAVE_PATH = \"C:/Users/JAEKYU/Documents/Jupyter Notebook/Pyqt5_Super_Resolution/Weight/Weight.ckpt\"\n",
    "        self.sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        if(not config.is_train):\n",
    "            saver.restore(self.sess, SAVE_PATH)\n",
    "            \n",
    "        else:\n",
    "            for epoch in range(15000):#15000\n",
    "                total_cost = 0\n",
    "                for i in range(total_batch):\n",
    "                    #batch 선언\n",
    "                    x_batch, y_batch = make_batch(self.input_data, self.label_data, batch_size=32)\n",
    "                    _, cost_val = self.sess.run([self.optimizer, self.cost], feed_dict={self.X : x_batch, self.Y : y_batch})\n",
    "                    total_cost = total_cost + cost_val\n",
    "\n",
    "                cost_training = total_cost / total_batch\n",
    "\n",
    "                if((epoch % 100) == 0):\n",
    "                    print(\"epoch : \", epoch+1, \"cost : \", cost_training)\n",
    "\n",
    "            saver.save(self.sess, SAVE_PATH)\n",
    "        \n",
    "    def testing(self, test_data):\n",
    "        #print(\"testing...\")\n",
    "        predict = self.sess.run(self.model, feed_dict={self.X : test_data})\n",
    "        predict = np.clip(predict, 0, 255).astype(np.uint8)\n",
    "        predict = np.array(predict)\n",
    "        predict_buff = np.zeros((self.input_size, self.input_size, self.channel_dim))\n",
    "        for row in range(self.input_size):\n",
    "            for col in range(self.input_size):\n",
    "                for channel in range(self.channel_dim):\n",
    "                    predict_buff[row][col][channel] = 255 - predict[0][row][col][channel]\n",
    "\n",
    "        plt.imshow(predict_buff)\n",
    "        plt.show()\n",
    "    def transform_image_high_quality(self, image_data):\n",
    "        predict = self.sess.run(self.model, feed_dict={self.X : image_data})\n",
    "        predict = np.clip(predict, 0, 255).astype(np.uint8)\n",
    "        predict_buff = np.zeros((self.input_size, self.input_size, self.channel_dim))\n",
    "        for row in range(self.input_size):\n",
    "            for col in range(self.input_size):\n",
    "                for channel in range(self.channel_dim):\n",
    "                    predict_buff[row][col][channel] = predict[0][row][col][channel]\n",
    "        predict_buff = np.clip(predict_buff, 0, 255).astype(np.uint8)\n",
    "\n",
    "        return predict_buff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:49: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:50: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:51: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n",
      "C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:52: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:/Users/JAEKYU/Documents/Jupyter Notebook/Pyqt5_Super_Resolution/Weight/Weight.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JAEKYU\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:59: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app = QApplication(sys.argv)\n",
    "    myWindow = SR_Window()\n",
    "    myWindow.show()\n",
    "    app.exec_()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
